#!/usr/bin/env python
"""
Gather all the case metadata and send it to the experiments databases
via a web post and SVN check-in

Created September, 2016

Author: CSEG <cseg@cgd.ucar.edu>
"""

from standard_script_setup import *

from CIME.case       import Case
from CIME.utils      import expect, append_status, is_last_process_complete

import base64
import datetime
import errno
import difflib
import filecmp
import getpass
import glob
import gzip
import json
import io
import re
import shlex
import shutil
import subprocess
import sys
from string import Template
import textwrap
import urllib, urllib2

logger = logging.getLogger(__name__)

# define global variables
_now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')

_expdb_url = 'https://csegwebdev.cgd.ucar.edu/expdb2.0'
_JSON_expdb_url = 'https://csegwebdev.cgd.ucar.edu/expdb2.0/cgi-bin/processJSON.cgi'
_query_expdb_url = 'https://csegwebdev.cgd.ucar.edu/expdb2.0/cgi-bin/query.cgi'
_SVN_expdb_url = 'https://svn-cesm2-expdb.cgd.ucar.edu'

_exp_types = ['CMIP6','production','development']

_XML_vars = ['CASE','COMPILER','COMPSET','CONTINUE_RUN','DOUT_L_MS',
             'DOUT_L_MSROOT','DOUT_S','DOUT_S_ROOT','GRID',
             'MACH','MPILIB','MODEL','MODEL_VERSION','REST_N','REST_OPTION',
             'RUNDIR','RUN_REFCASE','RUN_REFDATE','RUN_STARTDATE',
             'RUN_TYPE','STOP_N','STOP_OPTION','USER']

_run_vars = ['JOB_QUEUE','JOB_WALLCLOCK_TIME','PROJECT']

_archive_list = ['Buildconf','CaseDocs','CaseStatus','LockedFiles',
                 'Macros','README.case','SourceMods','software_environment.txt',
                 'timing','logs','postprocess']

_call_template = Template('in "$function" - Ignoring SVN repo update\n'
                          'SVN error executing command "$cmd". \n'
                          '$error: $strerror')

_copy_template = Template('in "$function" - Unable to copy "$source" to "$dest"'
                          '$error: $strerror')

# file patterns to ignore when checking into SVN
_IGNORE_PATTERNS = ['*.pyc','^.git','tmp','.svn','*~']

# file patterns to ignore when doing comparisons for SVN updates
# most of these are symbolic links back to CIME source tree
_EXCLUDE_FILES = ['archive_metadata','case.build',
                 'case.cmpgen_namelists','case.lt_archive','case.run',
                 'case.setup','case.st_archive','case.submit','check_case',
                 'check_input_data','preview_namelists','xmlchange','xmlquery',
                 '.env_mach_specific.csh','.env_mach_specific.sh',
                 'archive_files', 'Makefile', 'check_lockedfiles', 'getTiming',
                 'lt_archive.sh', 'mkDepends', 'mkSrcfiles', 'save_provenance']

_EXCLUDE_DIRS = ['archive_files','Tools']

# -------------------------------------------------------------------------------
# PasswordPromptAction class
# -------------------------------------------------------------------------------
class PasswordPromptAction(argparse.Action):
    def __init__(self,
             option_strings,
             dest=None,
             nargs=0,
             default=None,
             required=False,
             type=None,
             metavar=None,
             help=None):

        super(PasswordPromptAction, self).__init__(
             option_strings=option_strings,
             dest=dest,
             nargs=nargs,
             default=default,
             required=required,
             metavar=metavar,
             type=type,
             help=help)

    def __call__(self, parser, args, values, option_string=None):
        password = getpass.getpass()
        setattr(args, self.dest, password)

# ---------------------------------------------------------------------
# basic_authorization
# ---------------------------------------------------------------------
def basic_authorization(user, password):
    s = user + ":" + password
    return "Basic " + s.encode("base64").rstrip()

# ---------------------------------------------------------------------
# custom SVN Exception handler
# ---------------------------------------------------------------------
class SVNException(Exception):
    def __init__(self, value):
        self.value = value

    def __str__(self):
        return repr(self.value)

# -------------------------------------------------------------------------------
# commandline_options - parse any command line options
# -------------------------------------------------------------------------------

def commandline_options():
    """ Process the command line arguments.
    """
    parser = argparse.ArgumentParser(
        description='Query and parse the caseroot files to gather metadata information' \
            ' that can be posted to the CESM experiments database.' \
            ' ' \
            ' CMIP6 experiment case names must be reserved already in the' \
            ' experiment database. Please see:' \
            ' https://csesgweb.cgd.ucar.edu/expdb2.0 for details.')

    CIME.utils.setup_standard_logging_options(parser)

    parser.add_argument('--user', dest='user', type=str, default=None, required=True,
                        help='User name for SVN CESM developer access')

    parser.add_argument('--password', dest='password', action=PasswordPromptAction, type=str, default='', required=True,
                        help='Password for SVN CESM developer access')

    parser.add_argument('--caseroot', nargs=1, required=False, 
                        help='Fully quailfied path to case root directory (optional).' \
                            ' Defaults to current working directory.')

    parser.add_argument('--expType', nargs=1, required=True, choices=_exp_types,
                        help='Experiment type. For CMIP6 experiments, the case must already ' \
                             'exist in the experiments database at URL '\
                             ' http://csegweb.cgd.ucar.edu/expdb2.0. ' \
                             'Must be one of {0}'.format(_exp_types))

    parser.add_argument('--title', nargs=1, required=False, default=None,
                        help='Title of experiment (optional).')

    parser.add_argument('--ignoreLogs', action='store_true',
                        help='Ignore updating the SVN repository with the caseroot/logs files.' \
                            ' The experiments database and SVN repository will be updated.')

    parser.add_argument('--ignoreTiming', action='store_true',
                        help='Ignore updating the experiments database with timing data.')

    parser.add_argument('--ignoreRepoUpdate', action='store_true',
                        help='Ignore updating the SVN repository with all the caseroot files.' \
                            ' The experiments database will be updated.')

    parser.add_argument('--dryrun', action='store_true',
                        help='Parse settings and print what actions will be taken but' \
                            ' do not execute the action.')

    options = parser.parse_args()

    CIME.utils.handle_standard_logging_options(options)

    return options

# ---------------------------------------------------------------------
# get_case_vars
# ---------------------------------------------------------------------

def get_case_vars(case_dict, case):
    """ get_case_vars
    loop through the global list of XML vars and get the values
    from the case object into a case dictionary

    Arguments:
        case_dict (dict) - case dictionary to store XML variables
        case (object) - case object
    """
    logger.debug('get_case_vars')

    for xml_id in _XML_vars:
        case_dict[xml_id] = case.get_value(xml_id, resolved=True, subgroup=None)

    for xml_id in _run_vars:
        case_dict[xml_id] = case.get_value(xml_id, resolved=True, subgroup='case.run')

    return case_dict

# ---------------------------------------------------------------------
# get_pp_status
# ---------------------------------------------------------------------

def get_pp_status(case_dict):
    """ get_case_status
    Parse the postprocessing log files
    looking for status information

    Arguments:
        case_dict (dict) - case dictionary to store XML variables
    """
    logger.debug('get_pp_status')

    # initialize status variables
    msg_avg = dict()
    msg_diags = dict()
    comps = ['atm','ice','lnd','ocn']
    case_dict['tseries_status'] = 'Pending'
    case_dict['cmor_status'] = 'Pending'

    pp_log_dir =  os.path.join(case_dict['CASEROOT'],'postprocess','logs')

    msg_avg['atm'] = "Successfully completed generating atmosphere climatology averages"
    msg_diags['atm'] = "Successfully completed generating atmosphere diagnostics"

    msg_avg['ice'] = "Successfully completed generating ice climatology averages"
    msg_diags['ice'] = "Successfully completed generating ice diagnostics"

    msg_avg['lnd'] = "Successfully completed generating land climatology averages"
    msg_diags['lnd'] = "Successfully completed generating land diagnostics"

    msg_avg['ocn'] = "Successfully completed generating ocean climatology averages"
    msg_diags['ocn'] = "Successfully completed generating ocean diagnostics"

    for comp in comps:
        case_dict[comp+'_avg_status'] = 'Pending'
        case_dict[comp+'_diag_status'] = 'Pending'

        if os.path.exists(pp_log_dir+'/'+comp+'_averages.log'):
            log_file = os.path.join(pp_log_dir,comp+'_averages.log')
            if (is_last_process_complete(log_file, msg_avg[comp], 
                                         'Average list complies with standards.')):
                case_dict[comp+'_avg_status'] = 'Completed'
            else:
                case_dict[comp+'_avg_status'] = 'Unknown'

        if os.path.exists(pp_log_dir+'/'+comp+'_diagnostics.log'):
            log_file = os.path.join(pp_log_dir,comp+'_diagnostics.log')
            if (is_last_process_complete(log_file, msg_diags[comp], 'ncks version')):
                case_dict[comp+'_diag_status'] = 'Completed'
            else:
                case_dict[comp+'_diag_status'] = 'Unknown'

    if os.path.exists(pp_log_dir+'/timeseries.log'):
      log_file = os.path.join(pp_log_dir,'timeseries.log')
      if (is_last_process_complete(log_file, 'Successfully completed generating variable time-series files', 
                                   'cesm_tseries_generator.py')):
          case_dict['tseries_status'] = 'Completed'
      else:
          case_dict['tseries_status'] = 'Unknown'
              

    if os.path.exists(pp_log_dir+'/cmor.log'):
      log_file = os.path.join(pp_log_dir,'cmor.log')
      #TODO - need to check the CMOR log when it becomes available

    return case_dict


# ---------------------------------------------------------------------
# get_case_status
# ---------------------------------------------------------------------

def get_case_status(case_dict):
    """ get_case_status
    Parse the CaseStatus and postprocessing log files
    looking for status information

    Arguments:
        case_dict (dict) - case dictionary to store XML variables
    """
    logger.debug('get_case_status')

    # initialize status variables
    case_dict['run_status'] = 'Pending'
    case_dict['sta_status'] = 'Pending'
    case_dict['lta_status'] = 'Pending'

    cs = case_dict['CASEROOT']+'/CaseStatus'
    if os.path.exists(cs):
        # get the run status
        status = is_last_process_complete(cs, "case.run success", "case.run starting")
        case_dict['run_status'] = 'Complete'
        if status is False:
            case_dict['run_status'] = 'Unknown'

        # get the STA status
        if case_dict['DOUT_S']:
            status = is_last_process_complete(cs, "st_archive success", "st_archive starting")
            case_dict['sta_status'] = 'Complete'
            if status is False:
                case_dict['sta_status'] = 'Unknown'

        # get the LTA status
        if case_dict['DOUT_L_MS']:
            status = is_last_process_complete(cs, "lt_archive success", "lt_archive starting")
            case_dict['lta_status'] = 'Complete'
            if status is False:
                case_dict['lta_status'] = 'Unknown'

    # check if the postprocess dir exists in the caseroot
    case_dict['postprocess'] = False
    if os.path.exists(case_dict['CASEROOT']+'/postprocess'):
        case_dict['postprocess'] = True
        case_dict = get_pp_status(case_dict)

    return case_dict

# ---------------------------------------------------------------------
# check_expdb_case
# ---------------------------------------------------------------------
def check_expdb_case(case_dict, username, password):
    """ check_exp_case
    Cross check the casename with the database for a CMIP6 experiment

    Arguments:
        case_dict (dict) - case dictionary to store XML variables

    Return true if a matching casename exists in the database or
    false if not.
    """
    logger.debug('check_expdb_case')
    exists = False
    data_dict = { 'casename':case_dict['CASE'], 'queryType':'checkCaseExists'}
    data = json.dumps(data_dict)
    params = urllib.urlencode(dict(username=username, password=password, data=data))
    try:
        response = urllib2.urlopen(_query_expdb_url, params)
        html = response.read()
        if html.find('True'):
            exists = True
    except urllib2.HTTPError as http_e:
        logger.info('ERROR archive_metadata HTTP post failed "{0} - {1}"'.format(http_e.code, http_e.code))
    except urllib2.URLError as url_e:
        logger.info('ERROR archive_metadata URL failed "{0}"'.format(url_e.reason))

    return exists

# ---------------------------------------------------------------------
# create_JSON
# ---------------------------------------------------------------------

def create_JSON(case_dict):
    """ create_JSON
    Create a JSON file in the caseroot/archive_files dir.

    Arguments:
        case_dict (dict) - case dictionary to store XML variables
    """
    logger.debug('create_json')

    if not os.path.exists('{0}/archive_files'.format(case_dict['CASEROOT'])):
        os.makedirs('{0}/archive_files'.format(case_dict['CASEROOT']))

    filename = '{0}/archive_files/json.{1}'.format(case_dict['CASEROOT'], _now)
    with io.open(filename, 'w', encoding='utf-8') as f:
        f.write(unicode(json.dumps(case_dict, indent=4, sort_keys=True, ensure_ascii=True)))

# ---------------------------------------------------------------------
# post_JSON
# ---------------------------------------------------------------------

def post_JSON(case_dict, username, password):
    """ post_JSON
    Post a JSON file in the caseroot/archive_files to the 
    remote expdb URL.

    Arguments:
        case_dict (dict) - case dictionary to store XML variables
        username (string) - SVN developers username
        password (string) - SVN developers password
    """
    logger.debug('post_json')
    data = json.dumps(case_dict)
    params = urllib.urlencode(dict(username=username, password=password, data=data))
    try:
        response = urllib2.urlopen(_JSON_expdb_url, params)
    except urllib2.HTTPError as http_e:
        logger.info('ERROR archive_metadata HTTP post failed "{0} - {1}"'.format(http_e.code, http_e.code))
    except urllib2.URLError as url_e:
        logger.info('ERROR archive_metadata URL failed "{0}"'.format(url_e.reason))
                  
# ---------------------------------------------------------------------
# check_svn
# ---------------------------------------------------------------------
def check_svn():
    """ check_svn

    make sure svn client is installed and accessible
    """
    logger.debug('check_svn')

    cmd = ['svn','--version']
    try: 
        result = subprocess.check_output(cmd)
        if 'version' not in result:
            msg = 'SVN is not available. Ignoring SVN update'
            raise SVNException(msg)
    except subprocess.CalledProcessError as e:
        msg = _SVNError_template.substitute(function='check_svn',cmd=cmd,
                                            error=e.returncode, strerror=e.output)
        logger.info(msg)
        raise SVNException(msg)

# ---------------------------------------------------------------------
# create_temp_archive
# ---------------------------------------------------------------------
def create_temp_archive(case_dict):
    """ create_temp_archive

    Create a temporary SVN sandbox directory in the current caseroot
    """

    c = datetime.datetime.now()
    temp_archive_dir = '{0}/temp_archive_dir_{1}{2}{3}_{4}{5}'.format(case_dict['CASEROOT'], c.year,
                                                                      str(c.month).zfill(2), 
                                                                      str(c.day).zfill(2), 
                                                                      str(c.hour).zfill(2), 
                                                                      str(c.minute).zfill(2))

    logger.debug('create_temp_archive %s',temp_archive_dir)

    if not os.path.exists(temp_archive_dir):
        os.makedirs(temp_archive_dir)

    return temp_archive_dir

# ---------------------------------------------------------------------
# check_svn_repo
# ---------------------------------------------------------------------
def check_svn_repo(case_dict, username, password):
    """ check_svn_repo

    check if a SVN repo exists for this case
    """
    logger.debug('check_svn_repo')

    repo_exists = False
    svn_repo = '{0}/trunk'.format(case_dict['svn_repo_url'])
    cmd = ['svn','list', svn_repo, '--username', username, '--password', password]
    try:
        result = subprocess.check_output(cmd)
        if re.search('README.archive', result):
            repo_exists = True
    except subprocess.CalledProcessError as e:
        msg = 'SVN repo does not exist for this case. A new one will be created.'
        logger.warning(msg)

    return repo_exists


# ---------------------------------------------------------------------
# get_trunk_tag
# ---------------------------------------------------------------------
def get_trunk_tag(case_dict, username, password):
    """ get_trunk_tag

    return the most recent trunk tag as an integer
    """
    logger.debug('get_trunk_tag')

    tag = 0
    svn_repo = '{0}/trunk_tags'.format(case_dict['svn_repo_url'])
    cmd = ['svn','list', svn_repo, '--username', username, '--password', password]
    try: 
        result = subprocess.check_output(cmd)
        last_tag = [i for i in result.split('\n') if i][-1]
        last_tag = last_tag[:-1].split('_')[-1]
        tag = int(last_tag.strip('0'))
    except subprocess.CalledProcessError as e:
        msg = _call_template.substitute(function='get_trunk_tag',cmd=cmd,
                                        error=e.returncode, strerror=e.output)
        logger.warning(msg)
        raise SVNException(msg)

    return tag

# ---------------------------------------------------------------------
# checkout_repo
# ---------------------------------------------------------------------
def checkout_repo(case_dict, username, password):
    """ checkout_repo

    checkout the repo into the archive_temp_dir
    """
    logger.debug('checkout_repo')

    os.chdir(case_dict['archive_temp_dir'])
    svn_repo = '{0}/trunk'.format(case_dict['svn_repo_url'])
    cmd = ['svn', 'co', '--username', username,'--password', password, svn_repo, '.']
    try:
        result = subprocess.check_call(cmd)
    except subprocess.CalledProcessError as e:
        msg = _call_template.substitute(function='checkout_repo',cmd=cmd,
                                        error=e.returncode, strerror=e.output)
        logger.warning(msg)
        raise SVNException(msg)

    os.chdir(case_dict['CASEROOT'])

# ---------------------------------------------------------------------
# create_readme(case_dict)
# ---------------------------------------------------------------------
def create_readme(case_dict):
    """ create_readme

    Create a generic README.archive file
    """
    logger.debug('create_readme')
    
    os.chdir(case_dict['archive_temp_dir'])
    
    f = open('README.archive','w')
    f.write('Archived metadata is available for this case at URL:\n')
    f.write(_expdb_url)
    f.close()

# ---------------------------------------------------------------------
# update_local_repo
# ---------------------------------------------------------------------
def update_local_repo(case_dict, ignoreLogs):
    """ update_local_repo
    
    Compare and update local SVN sandbox
    """    
    logger.debug('update_local_repo')

    archive_temp_dir = os.path.basename(os.path.normpath(case_dict['archive_temp_dir']))
    from_dir = case_dict['CASEROOT']
    to_dir = case_dict['archive_temp_dir']

    # append the archive_temp_dir to the exclude list
    exclude_files = _EXCLUDE_FILES
    exclude_dirs = _EXCLUDE_DIRS
    exclude_dirs.append(archive_temp_dir)

    # *******************************************
    def update_temp_repo(arg, directory, fnames):
    # *******************************************
        """ update_local_svn 
        os.paty.walk handler function to copy and add files
        to the archive_temp_dir
        Note - this function must be nested in the update_local_repo
        function in order for the recursion to work correctly.
        """
        for filename in fnames:
            # exclude dirs that are in the exclude_dirs list
            for dir in exclude_dirs:
                if dir in filename or dir in directory:
                    return

            # only include files that aren't in the exclude_files list
            if filename not in exclude_files:
                # exclude all files ending with ~
                if filename[-1] == '~':
                    return

                src = os.path.join(directory, filename)
                dest = to_dir + src[len(from_dir):]
                logger.debug(src+' -> '+dest)
                if not os.path.exists(dest):
                    os.mkdir(dest)
                    cmd = ['svn', 'add', dest]
                    try:
                        result = subprocess.check_call(cmd)
                    except subprocess.CalledProcessError as e:
                        msg = _call_template.substitute(function='update_lcoal_repo',cmd=cmd,
                                                        error=e.returncode, strerror=e.output)
                        logger.warning(msg)
                        raise SVNException(msg)
                else:
                    shutil.copy2(src, dest)

    # copy and add files from caseroot to temp repo
    os.path.walk(case_dict['CASEROOT'], update_temp_repo, None)


    # *******************************************
    def remove_temp_repo(arg, directory, fnames):
    # *******************************************
        """ remove_local_svn 
        os.paty.walk handler function to remove files from 
        the archive_temp_dir that are no longer in the caseroot
        Note - this function must be nested in the update_local_repo
        function in order for the recursion to work correctly.
        """
        for filename in fnames:
            # exclude dirs that are in the exclude_dirs list
            for dir in exclude_dirs:
                if dir in filename or dir in directory:
                    return

            # only include files that aren't in the exclude_files list
            if filename not in exclude_files:
                # exclude all files ending with ~
                if filename[-1] == '~':
                    return

                # note - src is now the archive_temp_dir
                src = os.path.join(directory, filename)
                # and dest is the caseroot
                dest = to_dir + src[len(from_dir):]
                logger.debug(src+' -> '+dest)
                if not os.path.exists(dest):
                    os.mkdir(dest)
                    cmd = ['svn', 'rm', src]
                    try:
                        result = subprocess.check_call(cmd)
                    except subprocess.CalledProcessError as e:
                        msg = _call_template.substitute(function='remove_lcoal_repo',cmd=cmd,
                                                        error=e.returncode, strerror=e.output)
                        logger.warning(msg)
                        raise SVNException(msg)

    # detect deleted files in src and remove from temp repo
    os.path.walk(archive_temp_dir, remove_temp_repo, None)

    # check if ignoreLogs is specified
    if ignoreLogs:
        os.chdir(case_dict['archive_temp_dir'])
        if os.path.isdir('./logs'):
            try:
                shutil.rmtree('./logs')
            except OSError as e:
                logger.warning('in "update_local_repo" - Unable to remove "logs" in archive dir.')

            cmd = ['svn', 'delete', './logs']
            try:
                result = subprocess.check_call(cmd)
            except subprocess.CalledProcessError as e:
                msg = _call_template.substitute(function='update_lcoal_repo',cmd=cmd,
                                                error=e.returncode, strerror=e.output)
                logger.warning(msg)
                raise SVNException(msg)
         
        if os.path.isdir('./postprocess/logs'):
            os.chdir('./postprocess')
            try:
                shutil.rmtree('./logs')
            except OSError as e:
                logger.warning('in "update_local_repo" - Unable to remove "postprocess/logs" in archive dir.')

            cmd = ['svn', 'delete', './logs']
            try:
                result = subprocess.check_call(cmd)
            except subprocess.CalledProcessError as e:
                msg = _call_template.substitute(function='update_lcoal_repo',cmd=cmd,
                                                error=e.returncode, strerror=e.output)
                logger.warning(msg)
                raise SVNException(msg)

# ---------------------------------------------------------------------
# populate_local_repo
# ---------------------------------------------------------------------
def populate_local_repo(case_dict, ignoreLogs):
    """ populate_local_repo

    Populate local SVN sandbox
    """
    logger.debug('populate_local_repo')

    os.chdir(case_dict['CASEROOT'])

    # loop through the _archive_list and copy to the temp archive dir
    for archive in _archive_list:
        if os.path.exists(archive):
            if os.path.isdir(archive):
                try:
                    target = case_dict['archive_temp_dir']+'/'+archive
                    shutil.copytree(archive, target, symlinks=False, 
                                    ignore=shutil.ignore_patterns(*_IGNORE_PATTERNS))
                except OSError as e:
                    msg = _copy_template.substitute(function='populate_local_repo',
                                                    source=archive, dest=case_dict['archive_temp_dir'],
                                                    error=e.errno, strerror=e.strerror)
                    logger.warning(msg)
            else:
                try:
                    shutil.copy2(archive, case_dict['archive_temp_dir'])
                except OSError as e:
                    msg = _copy_template.substitute(function='populate_local_repo',
                                                    source=archive, dest=case_dict['archive_temp_dir'],
                                                    error=e.errno, strerror=e.strerror)
                    logger.warning(msg)

    # add files with .xml as the prefix
    xml_files = glob.glob('*.xml')
    for xml_file in xml_files:
        if os.path.isfile(xml_file):
            try:
                shutil.copy2(xml_file, case_dict['archive_temp_dir'])
            except OSError as e:
                msg = _copy_template.substitute(function='populate_local_repo',
                                                source=xml_file, dest=case_dict['archive_temp_dir'],
                                                error=e.errno, strerror=e.strerror)
                logger.warning(msg)
        
    # add files with user_ as the suffix
    user_files = glob.glob('user_*')
    for user_file in user_files:
        if os.path.isfile(user_file):
            try:
                shutil.copy2(user_file, case_dict['archive_temp_dir'])
            except OSError as e:
                msg = _copy_template.substitute(function='populate_local_repo',
                                                source=user_file, dest=case_dict['archive_temp_dir'],
                                                error=e.errno, strerror=e.strerror)
                logger.warning(msg)

        
    # add files with Depends as the suffix
    conf_files = glob.glob('Depends.*')
    for conf_file in conf_files:
        if os.path.isfile(conf_file):
            try:
                shutil.copy2(conf_file, case_dict['archive_temp_dir'])
            except OSError as e:
                msg = _copy_template.substitute(function='populate_local_repo',
                                                source=conf_file, dest=case_dict['archive_temp_dir'],
                                                error=e.errno, strerror=e.strerror)
                logger.warning(msg)

        
    # add files with casename as the suffix
    case_files = glob.glob('{0}.*'.format(case_dict['CASE']))
    for case_file in case_files:
        if os.path.isfile(case_file):
            try:
                shutil.copy2(case_file, case_dict['archive_temp_dir'])
            except OSError as e:
                msg = _copy_template.substitute(function='populate_local_repo',
                                                source=case_file, dest=case_dict['archive_temp_dir'],
                                                error=e.errno, strerror=e.strerror)
                logger.warning(msg)


    # check if ignoreLogs is specified
    if ignoreLogs:
        os.chdir(case_dict['archive_temp_dir'])
        if os.path.isdir('./logs'):
            try:
                shutil.rmtree('./logs')
            except OSError as e:
                logger.warning('in "populate_local_repo" - Unable to remove "logs" in archive dir.')
        
        if os.path.isdir('./postprocess/logs'):
            os.chdir('./postprocess')
            try:
                shutil.rmtree('./logs')
            except OSError as e:
                logger.warning('in "populate_local_repo" - Unable to remove "postprocess/logs" in archive dir.')


# ---------------------------------------------------------------------
# checkin_trunk
# ---------------------------------------------------------------------
def checkin_trunk(case_dict, svn_cmd, message,  username, password):
    """ checkin_trunk

    Check in the local SVN sandbox to the remote trunk
    """
    logger.debug('checkin_trunk')

    os.chdir(case_dict['archive_temp_dir'])
    svn_repo = '{0}/trunk'.format(case_dict['svn_repo_url'])
    msg = '"{0}"'.format(message)
    cmd = ['svn', svn_cmd, '--username', username, '--password', password, '.', '--message', msg]

    if svn_cmd in ['import']:
        # create the trunk dir
        msg = '"create trunk"'
        cmd = ['svn', 'mkdir', '--parents', svn_repo, '--username', username, '--password', password, '--message', msg]
        try:
            result = subprocess.check_call(cmd)
        except subprocess.CalledProcessError as e:
            msg = _call_template.substitute(function='checkin_trunk',cmd=cmd,
                                            error=e.returncode, strerror=e.output)
            logger.warning(msg)
            raise SVNException(msg)

        # create the trunk_tags dir
        tags = '{0}/trunk_tags'.format(case_dict['svn_repo_url'])
        msg = '"create trunk_tags"'
        cmd = ['svn', 'mkdir', tags, '--username', username, '--password', password, '--message', msg]
        try:
            result = subprocess.check_call(cmd)
        except subprocess.CalledProcessError as e:
            msg = _call_template.substitute(function='checkin_trunk',cmd=cmd,
                                            error=e.returncode, strerror=e.output)
            logger.warning(msg)
            raise SVNException(msg)

        msg = '"{0}"'.format(message)
        cmd = ['svn', svn_cmd, '--username', username, '--password', password, '.', svn_repo, '--message', msg]

    # check-in the trunk to svn
    try:
        result = subprocess.check_call(cmd)
    except subprocess.CalledProcessError as e:
        msg = _call_template.substitute(function='checkin_trunk',cmd=cmd,
                                        error=e.returncode, strerror=e.output)
        logger.warning(msg)
        raise SVNException(msg)

# ---------------------------------------------------------------------
# create_tag
# ---------------------------------------------------------------------
def create_tag(case_dict, new_tag, username, password):
    """ create_tag

    create a new trunk tag in the remote repo
    """
    logger.debug('create_tag')

    # create a new trunk tag
    os.chdir(case_dict['archive_temp_dir'])
    svn_repo = '{0}/trunk'.format(case_dict['svn_repo_url'])
    svn_repo_tag = '{0}/trunk_tags/{1}'.format(case_dict['svn_repo_url'],new_tag)
    msg = '"create new trunk tag"'
    cmd = ['svn', 'copy', '--username', username, '--password', password, svn_repo, svn_repo_tag, '--message', msg]
    try:
        result = subprocess.check_call(cmd)
    except subprocess.CalledProcessError as e:
        msg = _call_template.substitute(function='checkin_trunk',cmd=cmd,
                                        error=e.returncode, strerror=e.output)
        logger.warning(msg)
        raise SVNException(msg)

# ---------------------------------------------------------------------
# update_repo
# ---------------------------------------------------------------------
def update_repo(ignoreLogs, case_dict, username, password):
    """ update_repo

    Update SVN repo
    """
    logger.debug('update_repo')

    try:
        # check if svn client is installed
        check_svn()

        # check if the case repo exists
        case_dict['svn_repo_url'] = '{0}/{1}'.format(_SVN_expdb_url, case_dict['CASE'])
        repo_exists = check_svn_repo(case_dict, username, password)
        case_dict['archive_temp_dir'] = create_temp_archive(case_dict)

        if repo_exists:
            # need to update trunk and make a new tag
            last_tag = get_trunk_tag(case_dict, username, password)
            new_tag = '{0}_{1}'.format(case_dict['CASE'],str(last_tag+1).zfill(4))
            checkout_repo(case_dict, username, password)
            update_local_repo(case_dict, ignoreLogs)
            msg = 'update case metadata for {0} by {1}'.format(case_dict['CASE'],username)
            checkin_trunk(case_dict, 'ci', msg, username, password)
            create_tag(case_dict, new_tag, username, password)
            logger.info('SVN repository trunk updated at URL "%s"', case_dict['svn_repo_url'])
            logger.info('   and a new trunk tag created for  "%s"', new_tag)
        else:
            # create a new case repo
            new_tag = '{0}_0001'.format(case_dict['CASE'])
            create_readme(case_dict)
            populate_local_repo(case_dict, ignoreLogs)
            msg = 'initial import of case metadata for {0} by {1}'.format(case_dict['CASE'],username)
            checkin_trunk(case_dict, 'import', msg, username, password)
            create_tag(case_dict, new_tag, username, password)
            logger.info('SVN repository imported to trunk URL "%s"', case_dict['svn_repo_url'])
            logger.info('   and a new trunk tag created for  "%s"', new_tag)

    except SVNException as e:
        pass

    return case_dict


# ---------------------------------------------------------------------
# get_timing_data
# ---------------------------------------------------------------------
def get_timing_data(case_dict):
    """ get_timing_data
    parse the timing data file and add information to the case_dict

    Arguments:
        case_dict (dict) - case dictionary to store XML variables
    """
    logger.debug('get_timing_data')
    # initialize the timing values in the dictionary
    case_dict['model_cost'] = 'undefined'
    case_dict['model_throughput'] = 'undefined'

    if case_dict['run_status'] == 'Complete':
        timing_dir = case_dict['CASEROOT']+'/timing'
        last_time = ''
        if os.path.exists(timing_dir):
            # check if timing files exists
            timing_file_pattern = 'cesm_timing.'+case_dict['CASE']
            last_time = max(glob.glob(timing_dir+'/'+timing_file_pattern+'.*'), key=os.path.getctime)
            if len(last_time) > 0:
                if 'gz' in last_time:
                    # gunzip file first
                    with gzip.open(last_time, 'rb') as f:
                        file_content = f.readlines()
                else:
                    with open(last_time, 'r') as f:
                        file_content = f.readlines()
                        
                # search the file content for matching lines
                case_dict['model_cost'] = [line for line in file_content if 'Model Cost:' in line]
                case_dict['model_throughput'] = [line for line in file_content if 'Model Throughput:' in line]

    return case_dict


# ---------------------------------------------------------------------
# initialize_main
# ---------------------------------------------------------------------
def initialize_main(options):
    """ initialize_main

    Initialize the case dictionary data structure with command line options
    """
    logger.debug('intialize_main')

    case_dict = dict()

    case_dict['CASEROOT'] = os.getcwd()
    if options.caseroot:
        case_dict['CASEROOT'] = options.caseroot[0]

    username = None
    if options.user:
        username = options.user
        case_dict['svnlogin'] = username

    password = None
    if options.password:
        password = options.password

    if options.expType:
        case_dict['expType'] = options.expType[0]

    case_dict['title'] = None
    if options.title:
        case_dict['title'] = options.title[0]

    case_dict['dryrun'] = False
    if options.dryrun:
        case_dict['dryrun'] = True

    case_dict['archive_temp_dir'] = ''

    return case_dict, username, password

# ---------------------------------------------------------------------
# main
# ---------------------------------------------------------------------

def main(options):
    """ main

    Arguments:
        options (list) - input options from command line
    """
    logger.debug('main')

    (case_dict, username, password) = initialize_main(options)
 
    # loop through the _XML_vars gathering values
    with Case(case_dict['CASEROOT'], read_only=True) as case:
        if case_dict['dryrun']:
            logger.info('Dryrun - calling get_case_vars')
        else:
            case_dict = get_case_vars(case_dict, case)

    # check that the casename is reserved in the expdb 
    # for CMIP6 experiments
    if (case_dict['expType'].lower() == 'cmip6'):
        if case_dict['dryrun']:
            logger.info('Dryrun - calling check_expdb_case for CMIP6 experiment')
        else:
            if not check_expdb_case(case_dict, username, password):
                logger.info('Unable to archive CMIP6 metadata. '
                            '"%s" casename does not exist in database. '
                            'All CMIP6 experiments casenames must be '
                            'reserved in the experiments database at URL: '
                            '   https://csegweb.cgd.ucar.edu/expdb2.0'
                            'prior to running archive_metadata.',case_dict['CASE'])
                sys.exit(1)

    # get the case status into the case_dict 
    if case_dict['dryrun']:
        logger.info('Dryrun - calling get_case_status')
    else:
        case_dict = get_case_status(case_dict)

    # create / update the cesm expdb repo with the caseroot files
    if not options.ignoreRepoUpdate:
        if case_dict['dryrun']:
            logger.info('Dryrun - calling update_repo')
        else:
            case_dict = update_repo(options.ignoreLogs, case_dict,
                                    username, password)

    # parse the timing data into the case_dict
    if not options.ignoreTiming:
        if case_dict['dryrun']:
            logger.info('Dryrun - calling get_timing_data')
        else:
            case_dict = get_timing_data(case_dict)

    # create a JSON file containing the case_dict with the date appended to the filename
    if case_dict['dryrun']:
        logger.info('Dryrun - calling create_JSON')
    else:
        create_JSON(case_dict)

    # post the JSON to the remote DB
    if case_dict['dryrun']:
        logger.info('Dryrun - calling post_JSON')
    else:
        post_JSON(case_dict, username, password)

    # clean-up the temporary archive files dir
    if case_dict['dryrun']:
        logger.info('Dryrun - calling rmtree for temporary directory')
    else:
        if not options.ignoreRepoUpdate and os.path.exists(case_dict['archive_temp_dir']):
            shutil.rmtree(case_dict['archive_temp_dir'])

    logger.info('Successful completion of archive_metadata')


#===================================                                                           
if __name__ == "__main__":

    if ("--test" in sys.argv):
        test_results = doctest.testmod(verbose=True)
        sys.exit(1 if test_results.failed > 0 else 0)

    options = commandline_options()
    try:
        status = main(options)
        sys.exit(status)
    except Exception as error:
        print(str(error))
        sys.exit(1)
